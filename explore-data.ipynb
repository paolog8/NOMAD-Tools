{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f4f37e",
   "metadata": {},
   "source": [
    "# NOMAD Data Explorer\n",
    "\n",
    "This notebook demonstrates how to retrieve and analyze data from the NOMAD API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d17251",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "We'll use the authentication module from `nomad_auth.ipynb` to handle NOMAD API authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dab3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the authentication module from nomad_auth.ipynb\n",
    "%run './nomad_auth.ipynb'\n",
    "\n",
    "# After running nomad_auth, the following variables are available:\n",
    "# - api_client: NomadClient instance for making API calls\n",
    "# - current_token: The authenticated token\n",
    "# - current_user_info: Information about the authenticated user\n",
    "\n",
    "# Import our data retrieval module\n",
    "from nomad_api.data import (\n",
    "    get_all_samples_with_authors,\n",
    "    get_user_details,\n",
    "    get_all_unique_authors,\n",
    "    create_author_name_map,\n",
    "    query_sample_entries\n",
    ")\n",
    "\n",
    "# Import other required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Display the authentication UI\n",
    "display_auth_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587bfb8f",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Now that we're authenticated, we can start exploring NOMAD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50aa7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query payload to find samples\n",
    "query_payload = {\n",
    "    \"owner\": \"visible\",\n",
    "    \"query\": {\n",
    "        \"and\": [\n",
    "            {\"results.eln.sections:any\": [\"HySprint_Sample\"]},\n",
    "            {\"quantities:all\": [\"data\"]},\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "# Make sure we have an authenticated client\n",
    "if not api_client:\n",
    "    print(\"Please authenticate first using the UI above\")\n",
    "else:\n",
    "    # Make the API request\n",
    "    response_entries = api_client.make_request(\n",
    "        \"post\", \"entries/query\", json_data=query_payload\n",
    "    )\n",
    "    \n",
    "    # Print the number of entries found\n",
    "    print(f\"Found {response_entries.get('pagination', {}).get('total', 0)} matching entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data structure if entries were found\n",
    "if 'data' in response_entries and response_entries['data']:\n",
    "    print(f\"Number of entries returned: {len(response_entries['data'])}\")\n",
    "    # Show the keys of the first entry to understand the structure\n",
    "    print(\"\\nKeys in the first entry:\")\n",
    "    print(response_entries['data'][0].keys())\n",
    "else:\n",
    "    print(\"No data found or you need to authenticate first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f775bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine first entry in more detail if available\n",
    "if 'data' in response_entries and response_entries['data']:\n",
    "    entry = response_entries['data'][0]\n",
    "    print(f\"Entry ID: {entry.get('entry_id')}\")\n",
    "    print(f\"Upload ID: {entry.get('upload_id')}\")\n",
    "    # Show additional details from the first entry if they exist\n",
    "    if 'data' in entry and 'lab_id' in entry['data']:\n",
    "        print(f\"Lab ID: {entry['data']['lab_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea5819",
   "metadata": {},
   "source": [
    "# Collect Author Information for All Samples\n",
    "\n",
    "This section demonstrates how to collect information about authors for all samples in the NOMAD database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e431074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We are now using the imported functions from nomad_api.data\n",
    "# No need to redefine these functions in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa477ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all samples with author information (limiting to 5 pages for testing)\n",
    "# Remove the max_pages parameter to get all samples\n",
    "samples_data = get_all_samples_with_authors(api_client, page_size=50, max_pages=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba08c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "samples_df = pd.DataFrame(samples_data)\n",
    "\n",
    "# Display the first few rows\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eefcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to CSV for backup and further analysis\n",
    "samples_df.to_csv('nomad_samples_with_authors.csv', index=False)\n",
    "print(f\"Data saved to 'nomad_samples_with_authors.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a5ee38",
   "metadata": {},
   "source": [
    "# Enriching Author Information\n",
    "\n",
    "To make the data more useful for dashboards, let's enrich it by retrieving user details for the author IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We're now using the imported get_user_details function from nomad_api.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique author IDs from samples using our imported function\n",
    "unique_authors = get_all_unique_authors(samples_data)\n",
    "print(f\"Found {len(unique_authors)} unique authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5600825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from author IDs to names using our imported function\n",
    "user_id_to_name = create_author_name_map(api_client, samples_data)\n",
    "print(f\"Created name mapping for {len(user_id_to_name)} authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6799b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user names to the DataFrame\n",
    "samples_df['main_author_name'] = samples_df['main_author'].map(lambda x: user_id_to_name.get(x, 'Unknown'))\n",
    "\n",
    "# For coauthors (which is a list), add a new column with names\n",
    "def get_coauthor_names(coauthor_ids):\n",
    "    if not isinstance(coauthor_ids, list):\n",
    "        return []\n",
    "    return [user_id_to_name.get(user_id, 'Unknown') for user_id in coauthor_ids]\n",
    "\n",
    "samples_df['coauthor_names'] = samples_df['coauthors'].apply(get_coauthor_names)\n",
    "\n",
    "# Display the first few rows with author names\n",
    "samples_df[['entry_id', 'main_author', 'main_author_name', 'coauthor_names']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403f3fe",
   "metadata": {},
   "source": [
    "# Data Analysis and Dashboard Preparation\n",
    "\n",
    "Now let's analyze the data and create some visualizations for our dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72beb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count samples per main author\n",
    "author_sample_counts = samples_df['main_author_name'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "author_sample_counts.head(15).plot(kind='bar')\n",
    "plt.title('Number of Samples by Main Author (Top 15)', fontsize=14)\n",
    "plt.xlabel('Author')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70123781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Analyze sample creation over time\n",
    "\n",
    "# Convert upload_create_time to datetime\n",
    "samples_df['upload_date'] = pd.to_datetime(samples_df['upload_create_time'])\n",
    "\n",
    "# Extract year and month for time series analysis\n",
    "samples_df['year_month'] = samples_df['upload_date'].dt.to_period('M')\n",
    "\n",
    "# Count samples by month\n",
    "time_series = samples_df.groupby('year_month').size()\n",
    "\n",
    "# Plot time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "time_series.plot(kind='line', marker='o')\n",
    "plt.title('Sample Uploads Over Time', fontsize=14)\n",
    "plt.xlabel('Date (Year-Month)')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ffa0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analyze collaboration patterns (co-authorship)\n",
    "\n",
    "# Count number of coauthors per sample\n",
    "samples_df['coauthor_count'] = samples_df['coauthors'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Plot distribution of number of coauthors\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(samples_df['coauthor_count'], bins=range(0, max(samples_df['coauthor_count'])+2))\n",
    "plt.title('Distribution of Co-authors per Sample', fontsize=14)\n",
    "plt.xlabel('Number of Co-authors')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a16e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create collaboration network data (for network visualization)\n",
    "collaborations = []\n",
    "\n",
    "# For each sample, create pairs of collaborating authors\n",
    "for _, row in samples_df.iterrows():\n",
    "    main_author = row['main_author']\n",
    "    main_author_name = row['main_author_name']\n",
    "    \n",
    "    # Add collaboration between main author and each co-author\n",
    "    coauthors = row['coauthors']\n",
    "    if isinstance(coauthors, list) and len(coauthors) > 0:\n",
    "        for coauthor in coauthors:\n",
    "            coauthor_name = user_id_to_name.get(coauthor, 'Unknown')\n",
    "            collaborations.append((main_author_name, coauthor_name))\n",
    "\n",
    "# Count frequency of each collaboration\n",
    "from collections import Counter\n",
    "collaboration_counts = Counter(collaborations)\n",
    "\n",
    "# Print the top 10 most frequent collaborations\n",
    "print(\"Top 10 collaborations:\")\n",
    "for collab, count in collaboration_counts.most_common(10):\n",
    "    print(f\"{collab[0]} ↔ {collab[1]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a4375",
   "metadata": {},
   "source": [
    "# Prepare Data for Interactive Dashboard\n",
    "\n",
    "Let's prepare and save structured data for an interactive dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our dataframe to more dashboard-friendly formats\n",
    "\n",
    "# 1. Summary statistics\n",
    "dashboard_stats = {\n",
    "    'total_samples': int(len(samples_df)),\n",
    "    'total_authors': int(len(unique_authors)),\n",
    "    'published_samples': int(samples_df['published'].sum()),\n",
    "    'private_samples': int(len(samples_df) - samples_df['published'].sum()),\n",
    "    'samples_with_coauthors': int((samples_df['coauthor_count'] > 0).sum()),\n",
    "    'avg_coauthors_per_sample': float(samples_df['coauthor_count'].mean()),\n",
    "    'most_prolific_author': str(author_sample_counts.index[0]),\n",
    "    'most_prolific_author_count': int(author_sample_counts.iloc[0]),\n",
    "    'most_recent_upload': samples_df['upload_date'].max().strftime('%Y-%m-%d'),\n",
    "    'oldest_upload': samples_df['upload_date'].min().strftime('%Y-%m-%d'),\n",
    "}\n",
    "\n",
    "# Save summary stats\n",
    "with open('dashboard_summary_stats.json', 'w') as f:\n",
    "    json.dump(dashboard_stats, f, indent=2)\n",
    "\n",
    "print(\"Summary statistics saved for dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b983ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Time series data (monthly uploads)\n",
    "time_series_data = {\n",
    "    'dates': [str(period) for period in time_series.index],\n",
    "    'counts': [int(count) for count in time_series.values]  # Convert numpy.int64 to Python int\n",
    "}\n",
    "\n",
    "# Save time series data\n",
    "with open('dashboard_time_series.json', 'w') as f:\n",
    "    json.dump(time_series_data, f)\n",
    "\n",
    "# 3. Author statistics\n",
    "author_stats = []\n",
    "for author_name, count in author_sample_counts.items():\n",
    "    # Get author ID\n",
    "    author_id = None\n",
    "    for id, name in user_id_to_name.items():\n",
    "        if name == author_name:\n",
    "            author_id = id\n",
    "            break\n",
    "            \n",
    "    author_stats.append({\n",
    "        'author_name': author_name,\n",
    "        'author_id': author_id,\n",
    "        'sample_count': int(count),\n",
    "        # Additional metrics could be added here\n",
    "    })\n",
    "\n",
    "# Save author statistics\n",
    "with open('dashboard_author_stats.json', 'w') as f:\n",
    "    json.dump(author_stats, f, indent=2)\n",
    "\n",
    "# 4. Collaboration network data\n",
    "network_data = {\n",
    "    'nodes': [{'id': author, 'group': 1, 'size': author_sample_counts.get(author, 1)} \n",
    "              for author in set(user_id_to_name.values())],\n",
    "    'links': [{'source': source, 'target': target, 'value': count} \n",
    "              for (source, target), count in collaboration_counts.items()]\n",
    "}\n",
    "\n",
    "# Save network data\n",
    "with open('dashboard_network.json', 'w') as f:\n",
    "    # Convert any NumPy types to Python native types\n",
    "    network_data_serializable = json.loads(\n",
    "        json.dumps(network_data, default=lambda x: int(x) if hasattr(x, 'dtype') else x)\n",
    "    )\n",
    "    json.dump(network_data_serializable, f, indent=2)\n",
    "\n",
    "print(\"Data for interactive dashboard saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f673af1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We've collected comprehensive author information for all samples from NOMAD, structured this data for analysis, and created visualizations. The data has been saved in formats suitable for building interactive dashboards.\n",
    "\n",
    "The following files were created:\n",
    "\n",
    "1. `nomad_samples_with_authors.csv` - Raw data with all samples and their author information\n",
    "2. `dashboard_summary_stats.json` - Summary statistics for the dashboard\n",
    "3. `dashboard_time_series.json` - Time series data for charts\n",
    "4. `dashboard_author_stats.json` - Detailed author statistics\n",
    "5. `dashboard_network.json` - Collaboration network data for network visualizations\n",
    "\n",
    "These can be used with dashboard frameworks like Plotly Dash, Streamlit, or web-based visualization libraries like D3.js to create interactive dashboards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
